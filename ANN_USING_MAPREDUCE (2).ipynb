{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **HADOOP MAPREDUCE DISTRIBUTED ARTIFICIAL NEURAL NETWORK**"
      ],
      "metadata": {
        "id": "l6kS3MD2qBXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mrjob numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "F5NhITjqtxvv",
        "outputId": "3bac01f5-767f-4a3e-8f52-a3f815acff77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mrjob\n",
            "  Downloading mrjob-0.7.4-py2.py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from mrjob) (6.0.2)\n",
            "Downloading mrjob-0.7.4-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/439.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.6/439.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m430.1/439.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.6/439.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mrjob\n",
            "Successfully installed mrjob-0.7.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ANN THROUGH MAP-REDUCE (ON IRIS DATASET)\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "HPQO-IPRwse0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile neural_network.py\n",
        "import time\n",
        "from mrjob.job import MRJob\n",
        "from mrjob.step import MRStep\n",
        "import numpy as np\n",
        "from numpy import array, random, dot\n",
        "\n",
        "class NeuralNetwork(MRJob):\n",
        "\n",
        "    def configure_args(self):\n",
        "        super(NeuralNetwork, self).configure_args()\n",
        "        self.add_passthru_arg('--learning_rate', default=0.1, type=float,\n",
        "                              help='learning rate')\n",
        "        self.add_passthru_arg('--num_iterations', default=100, type=int,\n",
        "                              help='number of iterations')\n",
        "        self.add_passthru_arg('--hidden_layers', default='5,5', type=str,\n",
        "                              help='number of neurons in hidden layers')\n",
        "        self.add_passthru_arg('--l2_regularization', default=0.1, type=float,\n",
        "                              help='L2 regularization parameter')\n",
        "\n",
        "    def initialize_weights(self):\n",
        "        self.synaptic_weights = []\n",
        "        layer_sizes = [self.num_features] + \\\n",
        "            [int(x) for x in self.hidden_layers.split(',')] + [self.num_classes]\n",
        "        for i in range(len(layer_sizes)-1):\n",
        "            w = 2 * random.random((layer_sizes[i], layer_sizes[i+1])) - 1\n",
        "            self.synaptic_weights.append(w)\n",
        "\n",
        "    def activation_function(self, x):\n",
        "        return 1.0 / (1.0 + np.exp(-x))\n",
        "\n",
        "    def activation_derivative(self, x):\n",
        "        return x * (1 - x)\n",
        "\n",
        "    def feedforward(self, x):\n",
        "        activations = [x]\n",
        "        for i in range(len(self.synaptic_weights)):\n",
        "            dot_product = dot(activations[i], self.synaptic_weights[i])\n",
        "            activation = self.activation_function(dot_product)\n",
        "            activations.append(activation)\n",
        "        return activations\n",
        "\n",
        "    def backpropagation(self, x, y):\n",
        "        activations = self.feedforward(x)\n",
        "        y_onehot = np.zeros(self.num_classes)\n",
        "        y_onehot[y] = 1\n",
        "\n",
        "        error = [y_onehot - activations[-1]]\n",
        "        deltas = [error[-1] * self.activation_derivative(activations[-1])]\n",
        "\n",
        "        for i in range(len(self.synaptic_weights)-1, 0, -1):\n",
        "            error.append(dot(deltas[-1], self.synaptic_weights[i].T))\n",
        "            deltas.append(error[-1] * self.activation_derivative(activations[i]))\n",
        "        deltas.reverse()\n",
        "\n",
        "        for i in range(len(self.synaptic_weights)):\n",
        "            self.synaptic_weights[i] += self.learning_rate * \\\n",
        "                (dot(activations[i].reshape(-1, 1), deltas[i].reshape(1, -1)) +\n",
        "                 self.l2_regularization * self.synaptic_weights[i])\n",
        "\n",
        "    def mapper_init(self):\n",
        "        self.learning_rate = 0.1\n",
        "        self.num_iterations = 100\n",
        "        self.hidden_layers = \"4,3\"\n",
        "        self.l2_regularization = 0.01\n",
        "        self.num_features = 4\n",
        "        self.num_classes = 3\n",
        "        self.label_map = {'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2}\n",
        "        self.initialize_weights()\n",
        "        self.processed_samples = 0\n",
        "\n",
        "    def mapper(self, _, line):\n",
        "        # Skip header or empty lines\n",
        "        if not line.strip() or 'Id' in line or 'Species' in line:\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            # Parse the input line\n",
        "            data = line.strip().split(',')\n",
        "            if len(data) < 5:\n",
        "                return\n",
        "\n",
        "            # Convert features to float and ensure they're regular Python floats\n",
        "            features = array([float(x) for x in data[1:5]])\n",
        "            label = data[-1].strip()\n",
        "\n",
        "            if label not in self.label_map:\n",
        "                return\n",
        "\n",
        "            label_int = self.label_map[label]\n",
        "\n",
        "            # Train the network\n",
        "            for _ in range(self.num_iterations):\n",
        "                self.backpropagation(features, label_int)\n",
        "\n",
        "            # Get prediction and convert numpy types to Python native types\n",
        "            output = self.feedforward(features)[-1]\n",
        "            predicted_class = int(np.argmax(output))  # Convert to Python int\n",
        "            output_list = [float(x) for x in output]  # Convert to Python float list\n",
        "\n",
        "            # Yield with Python native types\n",
        "            yield str(label_int), {\n",
        "                'predicted_class': predicted_class,\n",
        "                'probabilities': output_list\n",
        "            }\n",
        "\n",
        "            self.processed_samples += 1\n",
        "\n",
        "        except Exception as e:\n",
        "            yield \"error\", str(e)\n",
        "\n",
        "    def reducer_init(self):\n",
        "        self.results = {str(i): {\n",
        "            'correct': 0,\n",
        "            'total': 0,\n",
        "            'predictions': []\n",
        "        } for i in range(3)}\n",
        "\n",
        "    def reducer(self, key, values):\n",
        "        if key == \"error\":\n",
        "            for value in values:\n",
        "                yield \"Error\", value\n",
        "            return\n",
        "\n",
        "        actual_class = int(key)\n",
        "        for value in values:\n",
        "            predicted_class = value['predicted_class']\n",
        "            probabilities = value['probabilities']\n",
        "\n",
        "            self.results[key]['total'] += 1\n",
        "            if predicted_class == actual_class:\n",
        "                self.results[key]['correct'] += 1\n",
        "            self.results[key]['predictions'].append(probabilities)\n",
        "\n",
        "    def reducer_final(self):\n",
        "        for class_label, data in self.results.items():\n",
        "            if data['total'] > 0:\n",
        "                accuracy = float(data['correct']) / float(data['total'])\n",
        "                avg_probs = np.mean(data['predictions'], axis=0) if data['predictions'] else [0.0] * self.num_classes\n",
        "\n",
        "                # Convert all numpy types to Python native types\n",
        "                result = {\n",
        "                    'samples_processed': int(data['total']),\n",
        "                    'correct_predictions': int(data['correct']),\n",
        "                    'accuracy': float(accuracy),\n",
        "                    'average_probabilities': [float(x) for x in avg_probs]\n",
        "                }\n",
        "\n",
        "                yield f\"Class {class_label}\", result\n",
        "\n",
        "    def steps(self):\n",
        "        return [\n",
        "            MRStep(mapper_init=self.mapper_init,\n",
        "                  mapper=self.mapper,\n",
        "                  reducer_init=self.reducer_init,\n",
        "                  reducer=self.reducer,\n",
        "                  reducer_final=self.reducer_final)\n",
        "        ]\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    NeuralNetwork.run()\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Output:\n",
        "This output suggests that the code has successfully run a neural network classifier using the perceptron algorithm\n",
        "to classify a dataset into three classes labeled as \"0.0\", \"1.0\", and \"2.0\".\n",
        "\n",
        "The output shows the class labels in the first column and the weights assigned to the two features used to classify the data in the second column.\n",
        "For example, the classifier assigned a weight of 0.4791666666666667 to the first feature and 0.5208333333333334 to the second feature to classify instances\n",
        "belonging to class \"2.0\".\n",
        "\n",
        "Similarly, for class \"1.0\", the classifier assigned a weight of 0.7887323943661971 to the first feature and 0.2112676056338028 to the second feature,\n",
        "and for class \"0.0\", the classifier assigned a weight of 0.6101694915254238 to the first feature and 0.3898305084745763 to the second feature.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wX6tCj3HtyQj",
        "outputId": "f0498af0-4fc4-4313-db85-47a44f4eb005"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting neural_network.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !chmod +x neural_network.py\n",
        "!chmod +x neural_network.py"
      ],
      "metadata": {
        "id": "cEtxoofwuG3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python neural_network.py \"/content/drive/MyDrive/ANN MAPREDUCE DATASET/Iris.csv\" > output.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vW-UNRigxOGI",
        "outputId": "8197741d-a029-470e-c266-9db70e5b63d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for inline runner\n",
            "Creating temp directory /tmp/neural_network.root.20241030.192213.418051\n",
            "Running step 1 of 1...\n",
            "job output is in /tmp/neural_network.root.20241030.192213.418051/output\n",
            "Streaming final output from /tmp/neural_network.root.20241030.192213.418051/output...\n",
            "Removing temp directory /tmp/neural_network.root.20241030.192213.418051...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat output.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QLj71QF39Mt",
        "outputId": "d0dc357c-ccf8-4dd3-bde8-0fbf6c1b7362"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Class 0\"\t{\"samples_processed\": 50, \"correct_predictions\": 50, \"accuracy\": 1.0, \"average_probabilities\": [0.9727167698843242, 0.02622352395388161, 0.030448172976813476]}\n",
            "\"Class 1\"\t{\"samples_processed\": 50, \"correct_predictions\": 22, \"accuracy\": 0.44, \"average_probabilities\": [0.5752634958600781, 0.42563008454115914, 0.02351538979056609]}\n",
            "\"Class 2\"\t{\"samples_processed\": 50, \"correct_predictions\": 35, \"accuracy\": 0.7, \"average_probabilities\": [0.014422626471982274, 0.3218506785500645, 0.6815229511282436]}\n"
          ]
        }
      ]
    }
  ]
}